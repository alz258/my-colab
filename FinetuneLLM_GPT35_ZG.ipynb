{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Rp80dTGpsDD"
   },
   "source": [
    "### Set up the project environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lx4wV2MIUJ8A",
    "outputId": "122d57be-f26c-4270-9f4d-62cd7f7f8ae5"
   },
   "outputs": [],
   "source": [
    "!pip install openai==1.7.2 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qypdUNULptjB"
   },
   "source": [
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFmEp0r5T2eI",
    "outputId": "89d94f66-e58f-46da-8c58-1ecf8137708f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Modules are imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfVAcV_XqDja"
   },
   "source": [
    "Setting up the OpenAI API:\n",
    "\n",
    "* Prepare a .env file to store the OpenAI API key.\n",
    "* Uploading the .env file to our colab environment\n",
    "* Load the API key and setup the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbXC4QM4qCBe"
   },
   "outputs": [],
   "source": [
    "load_dotenv('apikey.env.text')\n",
    "APIKEY = os.getenv(\"APIKEY\")\n",
    "ORGID = os.getenv(\"ORGID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWxipGQIpxH8"
   },
   "source": [
    "Creating OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "nHj-RaA5p0WE",
    "outputId": "688b427b-afd8-4dbf-b377-4eb3493be839"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=APIKEY,\n",
    "    organization=ORGID\n",
    ")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0r2XnfwnqTCK"
   },
   "source": [
    "### Prepare the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_Alc-CyuHmE"
   },
   "source": [
    "Loading the provided `Customer Complaints.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jan2OKk5qW1J",
    "outputId": "efcf04ab-6513-4075-bc07-ec00573f2669"
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"Customer Complaints.csv\")\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIK863G-qvMN"
   },
   "source": [
    "**Converting the Complaints records to json**\n",
    "\n",
    "To be able to use the data for the fine-tuning purpose, we first need to convert each row of the dataframe into the following format:\n",
    "\n",
    "<pre>\n",
    "<code>\n",
    "{\n",
    "  <span style=\"color: blue;\">\"messages\"</span>: [\n",
    "    {\n",
    "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"system\"</span>,\n",
    "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">Providing context about the user's prompt.\n",
    "                  It may include information about the task,\n",
    "                  instructions, or background details relevant\n",
    "                  to the conversation.</span>\"\n",
    "    },\n",
    "    {\n",
    "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"user\"</span>,\n",
    "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">the prompt or input provided by the user,\n",
    "                  which typically initiates the conversation with the assistant.</span>\"\n",
    "    },\n",
    "    {\n",
    "      <span style=\"color: blue;\">\"role\"</span>: <span style=\"color: red;\">\"assistant\"</span>,\n",
    "      <span style=\"color: blue;\">\"content\"</span>: \"<span style=\"color: green;\">The desired response or output generated by\n",
    "                  the assistant in response to the user's prompt.</span>\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "</code>\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWVCfuvRjdXa"
   },
   "source": [
    "define a method that get's a row of the dataframe and convert it into the json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tHnvRamq5NK"
   },
   "outputs": [],
   "source": [
    "def save_as_json(row):\n",
    "\n",
    "  system_content = \"\"\"\n",
    "      Given a customer complaint text, extract and return the following information in json (dict) format:\n",
    "      - Topic: The product/department that the customer has a complaint about.\n",
    "      - Problem: A two or three-word description of what exactly the problem is.\n",
    "      - Customer_Dissatisfaction_Index: is a number between 0 and 100 showing\n",
    "             how angry the customer is about the problem.\n",
    "  \"\"\"\n",
    "\n",
    "  formatted_data = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": row.Complaints},\n",
    "            {\"role\": \"assistant\", \"content\": row.Details}\n",
    "        ]\n",
    "      }\n",
    "\n",
    "  with open(\"training_data.json\", \"a\") as json_file:\n",
    "        json.dump(formatted_data, json_file)\n",
    "        json_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3haPgzI-ClF"
   },
   "source": [
    "use of this method to generate the `training_data.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNOMxwSX8dE4"
   },
   "outputs": [],
   "source": [
    "for index, row in training_data.iterrows():\n",
    "  save_as_json(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo9HFdW0jput"
   },
   "source": [
    "###  Fine-tune GPT 3.5 based on our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4TMhzSNj4hH"
   },
   "source": [
    "import the json file we prepared as our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "ExJ2cRU5-XtH",
    "outputId": "54ab1441-2c44-44a3-e396-479c3cf96673"
   },
   "outputs": [],
   "source": [
    "data_file = client.files.create(\n",
    "  file=open(\"training_data.json\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "data_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiBcO3I0kIU5"
   },
   "source": [
    "Create the Fine Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXJB348zkMSx"
   },
   "outputs": [],
   "source": [
    "fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "    training_file=data_file.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 'auto'\n",
    "     #   \"batch_size\": 8,\n",
    "    #  \"learning_rate_multiplier\": 0.3\n",
    "    }\n",
    ")\n",
    "fine_tuning_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7XWcO_7kzY6"
   },
   "source": [
    "retrieve the state of the fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "hpbHjWu3AS4k",
    "outputId": "93fc09ee-5182-4b0f-c06a-681f5279f259"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "  time.sleep(2)\n",
    "  retrieved_job = client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\n",
    "  status = retrieved_job.status\n",
    "  print(status)\n",
    "\n",
    "  if status == \"succeeded\":\n",
    "    print(\"Job done!\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XB-sFc3kO4A"
   },
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_3bNsW3k_eR"
   },
   "source": [
    "retrieve the event messages to check out the learning process of our fine-tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2bif68aIEGJ"
   },
   "outputs": [],
   "source": [
    "events = list(client.fine_tuning.jobs.list_events(fine_tuning_job_id=retrieved_job.id , limit=100).data)\n",
    "\n",
    "for e in events:\n",
    "  print(e.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe3jUJJjyeO1"
   },
   "source": [
    "extract the training loss in each learning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqhDoVBNzW_w"
   },
   "outputs": [],
   "source": [
    "step =[]\n",
    "train_loss = []\n",
    "\n",
    "for e in events:\n",
    "  if (e.data):\n",
    "    step.append(e.data(\"step\"))\n",
    "    train_loss.append(e.data[\"train_loss\"])\n",
    "\n",
    "print(step)\n",
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiiJIUuq2W4D"
   },
   "source": [
    "Use a line chart to visualize the train_loss in each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "EMRvEd-F2bLO",
    "outputId": "a717c4da-2d32-462c-8b5b-184a7969436b"
   },
   "outputs": [],
   "source": [
    "plt.plot(step, train_loss, marker ='o', linestyle='-')\n",
    "\"\"\"\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.title('Training Loss Over Steps')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lGyZnvk25q9"
   },
   "source": [
    "###  Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYljL-wH42ce"
   },
   "source": [
    "check `retrieved_job` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4ChDCWo3H85"
   },
   "outputs": [],
   "source": [
    "myLLM = retrieved_job.fine_tuned_model\n",
    "print(myLLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLLfuwC4-h9K"
   },
   "source": [
    "Defining a method to extract information from a given user complaint using a specific LLM and return the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3_99_Hf5CV1"
   },
   "outputs": [],
   "source": [
    "def extract_details(user_complaint, model_name):\n",
    "    \"\"\"\n",
    "    This function extracts information from a given user complaint using a specific LLM (Large Language Model).\n",
    "\n",
    "    Parameters:\n",
    "    user_complaint (str): The text of the user's complaint.\n",
    "    model_name (str): The name of the specific LLM model to use for extraction.\n",
    "    \"\"\"\n",
    "\n",
    "    system_content = \"\"\"\n",
    "        Given a customer complaint text, extract and return the following information in JSON (dict) format:\n",
    "        - Topic\n",
    "        - Problem\n",
    "        - Customer_Dissatisfaction_Index\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a response using the specified model and the user's complaint\n",
    "    response = client.chat.completions.create(\n",
    "        model = model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_content},  # System content explaining the expected output\n",
    "            {\"role\": \"user\", \"content\": user_complaint}  # User's complaint passed as content\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Return the content of the generated response\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zE_O2zAwplof"
   },
   "source": [
    "use the fine-tuned model to extract the details for the following user complaint:\n",
    "\n",
    "*TV channels keep disappearing from my subscription! What's going on? Extremely annoyed with this service!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vD1dEjnzWTuw"
   },
   "outputs": [],
   "source": [
    "complaint = \"TV channels keep disappearing from my subscription! What's going on? Extremely annoyed with this service!\"\n",
    "\n",
    "extract_details(complaint, myLLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJNgLZoS6-gw"
   },
   "source": [
    "test our `GPT-4` model with the same user complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2XBuw0N47AC"
   },
   "outputs": [],
   "source": [
    "extract_details(complaint, \"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVQQfAAXy-v8"
   },
   "outputs": [],
   "source": [
    "customer_complaint = \"I am very Angry! I want my money back!\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
